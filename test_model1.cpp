#include <tensorflow/c/c_api.h>
#include <opencv2/opencv.hpp>
#include <iostream>
#include <vector>


//·ªû ch∆∞∆°ng tr√¨nh n√†y th√¨ input truy·ªÅn v√†o ƒëang l√† m·ªôt ·∫£nh rgb m√†u tr·∫Øng, ·∫£nh n√†y t·ª± t·∫°o b·∫±ng  


void NoOpDeallocator(void* data, size_t a, void* b) {}

int main() {
    std::cout << "TensorFlow Version: " << TF_Version() << std::endl;

    // üîπ 1. Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng TensorFlow
    TF_Status* status = TF_NewStatus();
    TF_Graph* graph = TF_NewGraph();
    TF_SessionOptions* sess_opts = TF_NewSessionOptions();
    TF_Buffer* run_opts = nullptr;
    const char* tags[] = {"serve"};  // Th√™m tag-set "serve"
    TF_Session* session = TF_LoadSessionFromSavedModel(sess_opts, run_opts, "model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model", tags, 1, graph, nullptr, status);

    if (TF_GetCode(status) != TF_OK) {
        std::cerr << " L·ªói khi load model: " << TF_Message(status) << std::endl;
        return -1;
    }
    std::cout << " Model loaded successfully!" << std::endl;

    // üîπ 2. T·∫°o tensor ƒë·∫ßu v√†o (gi·∫£ s·ª≠ input shape l√† [1, 320, 320, 3])
    int64_t dims[] = {1, 320, 320, 3};  
    //std::vector<float> input_data(320 * 320 * 3, 1.0f); // D·ªØ li·ªáu ƒë·∫ßu v√†o to√†n 1.0
    //TF_Tensor* input_tensor = TF_NewTensor(TF_UINT8, dims, 4, input_data.data(), input_data.size() * sizeof(float), NoOpDeallocator, nullptr);
    std::vector<uint8_t> input_data(320 * 320 * 3, 255);  // Gi√° tr·ªã pixel 0-255
    TF_Tensor* input_tensor = TF_NewTensor(TF_UINT8, dims, 4, input_data.data(), input_data.size(), NoOpDeallocator, nullptr);
    // üîπ 3. T√¨m input & output trong graph


    TF_Operation* input_op = TF_GraphOperationByName(graph, "serving_default_input_tensor");
    TF_Operation* output_op = TF_GraphOperationByName(graph, "StatefulPartitionedCall:5");

    if (!input_op) {
        std::cerr << "Kh√¥ng t√¨m th·∫•y tensor ƒë·∫ßu v√†o: serving_default_input_tensor!" << std::endl;
    }
    if (!output_op) {
        std::cerr << "Kh√¥ng t√¨m th·∫•y tensor ƒë·∫ßu ra: StatefulPartitionedCall!" << std::endl;
    }





    if (!input_op || !output_op) {
        std::cerr << " Kh√¥ng t√¨m th·∫•y input/output trong graph!" << std::endl;
        return -1;
    }

    // üîπ 4. Ch·∫°y m√¥ h√¨nh
    TF_Output inputs[] = {{input_op, 0}};
    TF_Output outputs[] = {{output_op, 0}};
    TF_Tensor* output_tensor = nullptr;

    TF_SessionRun(session, nullptr, 
                  inputs, &input_tensor, 1, 
                  outputs, &output_tensor, 1, 
                  nullptr, 0, nullptr, status);

    if (TF_GetCode(status) != TF_OK) {
        std::cerr << " L·ªói khi ch·∫°y m√¥ h√¨nh: " << TF_Message(status) << std::endl;
        return -1;
    }
    std::cout << " Inference th√†nh c√¥ng!" << std::endl;

    // üîπ 5. L·∫•y k·∫øt qu·∫£ t·ª´ tensor ƒë·∫ßu ra
    float* output_data = static_cast<float*>(TF_TensorData(output_tensor));
    std::cout << "üîπ Gi√° tr·ªã ƒë·∫ßu ra ƒë·∫ßu ti√™n: " << output_data[0] << std::endl;

    // üîπ 6. Gi·∫£i ph√≥ng b·ªô nh·ªõ
    TF_DeleteTensor(input_tensor);
    TF_DeleteTensor(output_tensor);
    TF_DeleteSession(session, status);
    TF_DeleteGraph(graph);
    TF_DeleteSessionOptions(sess_opts);
    TF_DeleteStatus(status);

    return 0;
}
